{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import mxnet as mx \n",
    "from mxnet import gluon,autograd,nd\n",
    "import mxnet.ndarray as F\n",
    "from mxnet.gluon.model_zoo import vision\n",
    "from data_loader import videoFolder\n",
    "import utils\n",
    "from option import Options, args_\n",
    "from multiprocessing import cpu_count\n",
    "from network import lstm_net,resnet18_v2\n",
    "from metrics import L2Loss_2, L2Loss_cos\n",
    "import sys\n",
    "#import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    frames = args.frames\n",
    "    caption_length = args.caption_length\n",
    "    glove_file = args.glove_file\n",
    "    \n",
    "    #CPU_COUNT = multiprocessing.cpu_count()\n",
    "    if args.cuda:\n",
    "        ctx = mx.gpu()\n",
    "    else:\n",
    "        ctx = mx.cpu()\n",
    "    \n",
    "    if args.load_pretrain:\n",
    "        pretrain_model = vision.vgg16_bn(pretrained=True,ctx=ctx)\n",
    "        transform = utils.Compose([utils.ToTensor(ctx),\n",
    "                               utils.normalize(ctx),\n",
    "                               utils.extractFeature(ctx,pretrain_model)\n",
    "                             ])\n",
    "    else:\n",
    "        pretrain_model = None\n",
    "        transform = utils.Compose([utils.ToTensor(ctx),\n",
    "                                   utils.normalize(ctx),\n",
    "                                 ])\n",
    "    \n",
    "    target_transform = utils.targetCompose([utils.WordToTensor(ctx)])\n",
    "\n",
    "    train_dataset = videoFolder(args.train_folder,args.train_dict, frames, glove_file, \n",
    "                    caption_length, ctx, transform=transform, target_transform=target_transform)\n",
    "\n",
    "    test_dataset = videoFolder(args.test_folder,args.test_dict, frames, glove_file, \n",
    "                        caption_length, ctx, transform=transform, target_transform=target_transform)\n",
    "\n",
    "    train_loader = gluon.data.DataLoader(train_dataset,batch_size=args.batch_size,\n",
    "                                last_batch='keep',shuffle=True)\n",
    "\n",
    "    test_loader = gluon.data.DataLoader(test_dataset,batch_size=args.batch_size,\n",
    "                                    last_batch='keep',shuffle=False)\n",
    "\n",
    "    loss = L2Loss_2()\n",
    "    #net = lstm_net(frames,caption_length,ctx,pretrained=args.load_pretrain)\n",
    "    net = resnet18_v2(caption_length=caption_length,ctx=ctx)\n",
    "                            \n",
    "            \n",
    "    net.collect_params().initialize(init=mx.initializer.MSRAPrelu(), ctx=ctx)\n",
    "        \n",
    "    trainer = gluon.Trainer(net.collect_params(), 'adam',\n",
    "                            {'learning_rate': args.lr})\n",
    "    \n",
    "    smoothing_constant = 0.01\n",
    "    \n",
    "    for e in range(args.epochs):\n",
    "        \n",
    "        epoch_loss = 0.\n",
    "        batch_loss = None\n",
    "        for batch_id, (x,_) in enumerate(train_loader):\n",
    "            \n",
    "            if batch_id > 0:\n",
    "                batch_loss = F.mean(batch_loss).asscalar()\n",
    "                epoch_loss = (1 - smoothing_constant)*epoch_loss + smoothing_constant*batch_loss\n",
    "                \n",
    "            with autograd.record():\n",
    "                pred = net(x)\n",
    "                batch_loss = loss(pred,_)\n",
    "            \n",
    "            trainer.step(x.shape[0],ignore_stale_grad=True)\n",
    "            batch_loss.backward()\n",
    "            mx.nd.waitall()\n",
    "            \n",
    "            \n",
    "            if (batch_id+1) % 100 == 0:\n",
    "                print(\"Train Batch:{}, batch_loss:{}\".format(batch_id+1, epoch_loss))\n",
    "            \n",
    "            if ((batch_id == 0) and (e == 0)):\n",
    "                epoch_loss = F.mean(batch_loss).asscalar() \n",
    "        \n",
    "        \n",
    "        epoch_loss_1 = 0.\n",
    "        batch_loss_1 = None\n",
    "        for batch_id, (x,_) in enumerate(test_loader):\n",
    "            \n",
    "            if batch_id > 0:\n",
    "                batch_loss_1 = F.mean(batch_loss_1).asscalar()\n",
    "                epoch_loss_1 = (1 - smoothing_constant)*epoch_loss_1 + smoothing_constant*batch_loss_1\n",
    "                \n",
    "            with autograd.predict_mode():\n",
    "                predict = net(x)\n",
    "                batch_loss_1 = loss(pred,_)\n",
    "                batch_loss_1 = F.mean(batch_loss_1).asscalar()\n",
    "            \n",
    "            if (batch_id+1) % 30 == 0:\n",
    "                print(\"Test Batch:{}, batch_loss:{}\".format(batch_id+1, epoch_loss_1))\n",
    "                \n",
    "            if ((batch_id == 0) and (e == 0)):\n",
    "                epoch_loss_1 = F.mean(batch_loss_1).asscalar() \n",
    "            \n",
    "        print(\"Epoch {}, train_loss:{}, test_loss:{}\".format(e+1, epoch_loss, epoch_loss_1))\n",
    "    \n",
    "    if args.save_model == True:\n",
    "        file_name = \"./saved_model/\" + \"lstm_pretrain.params\"\n",
    "        net.save_parameters(file_name)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    args = args_()\n",
    "    train(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
